# Sleep Coach LLM System - Code Flow Documentation

## Overview
The Sleep Coach LLM system is a layered architecture that processes sleep data, provides personalized insights, and answers questions using a local LLM (Llama) with vector database integration.

---

## ğŸ”„ System Architecture Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI Application (app.py)              â”‚
â”‚  - REST API endpoints                                        â”‚
â”‚  - Request/Response handling                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SleepCoachLLM (Main Orchestrator)              â”‚
â”‚  - Initializes all components                               â”‚
â”‚  - Coordinates query processing                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Analytics   â”‚ â”‚ Vector DB     â”‚ â”‚  Privacy     â”‚
â”‚  Database    â”‚ â”‚ (Qdrant)      â”‚ â”‚  Processor   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Component Initialization Flow

### 1. **Application Startup** (`app.py` â†’ `startup_event()`)
```
1. Load environment variables (.env)
2. Validate configuration (Config.validate())
3. Initialize SleepCoachLLM() â†’ Triggers component initialization
```

### 2. **SleepCoachLLM Initialization** (`sleep_coach_llm.py`)
```python
SleepCoachLLM.__init__()
â”œâ”€â”€ PrivacyProcessor()          # Handles user ID pseudonymization
â”œâ”€â”€ AnalyticsDatabase()          # MySQL connection for sleep data
â”œâ”€â”€ CohortAnalytics()            # Cohort comparison metrics
â”œâ”€â”€ VectorDatabase()            # Qdrant vector DB for knowledge base
â”œâ”€â”€ SleepCoachAgent()           # Main query processing agent
â””â”€â”€ ConversationLogger()         # Session logging
```

### 3. **Component Initialization Details**

#### **AnalyticsDatabase** (MySQL)
```
1. Connect to MySQL database (Config.DB_CONFIG)
2. Resolve table names (summary/details tables)
3. Get table columns dynamically
4. Store connection for query execution
```

#### **VectorDatabase** (Qdrant)
```
1. Initialize CustomEmbeddingClient (connects to embedding API)
2. Connect to Qdrant server (Config.QDRANT_URL)
3. Verify collection exists (Config.QDRANT_COLLECTION_NAME)
4. Fallback to mock if connection fails
```

#### **SleepCoachAgent**
```
1. Initialize LlamaClient (for LLM queries)
2. Initialize QueryClassifier (uses Llama)
3. Initialize SQLAgent (uses Llama + Analytics DB)
4. Set up tools (Analytics, Cohort, Knowledge, Chart)
```

---

## ğŸ” Query Processing Flow

### Main Entry Point: `handle_user_query(user_id, query)`

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Query Received                                     â”‚
â”‚  "How was my sleep over the last 7 days?"               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: Privacy Processing                              â”‚
â”‚  - Convert user_id to pseudonymized ID (for logging)    â”‚
â”‚  - Keep original customer_id for DB queries            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: Agent Processing (process_query)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Query Classifier                                  â”‚ â”‚
â”‚  â”‚  - Check if query is sleep-related                 â”‚ â”‚
â”‚  â”‚  - Classify into:                                  â”‚ â”‚
â”‚  â”‚    â€¢ Data Pull (SQL)                               â”‚ â”‚
â”‚  â”‚    â€¢ Knowledge                                     â”‚ â”‚
â”‚  â”‚    â€¢ LLM Core                                     â”‚ â”‚
â”‚  â”‚    â€¢ Off-Topic (routed to LLM Core)              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚               â”‚
        â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Pull    â”‚ â”‚  Knowledge   â”‚ â”‚  LLM Core    â”‚
â”‚ (SQL)        â”‚ â”‚              â”‚ â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Query Type Processing Details

### **Type 1: Data Pull (SQL) Query**
Example: *"How was my sleep over the last 7 days?"*

```
1. QueryClassifier.classify()
   â””â”€> Returns: "Data Pull (SQL)"

2. SQLAgent.generate_sql(query, customer_id)
   â”œâ”€> Uses Llama to generate SQL query
   â”œâ”€> Provides database schema context
   â””â”€> Returns SQL query

3. SQLAgent.run_query(sql_query)
   â”œâ”€> Execute SQL on MySQL database
   â”œâ”€> Serialize results (dates, decimals)
   â””â”€> Return data rows

4. Format Response
   â”œâ”€> If â‰¤50 rows: Use raw data summary
   â””â”€> If >50 rows: Use Llama for formatting

5. Return Response
   â””â”€> Contains: sql_query, results, content, total_rows
```

### **Type 2: Knowledge Query**
Example: *"What's the importance of REM sleep?"*

```
1. QueryClassifier.classify()
   â””â”€> Returns: "Knowledge"

2. VectorDatabase.similarity_search(query, k=3)
   â”œâ”€> CustomEmbeddingClient.embed_query(query)
   â”‚   â””â”€> POST to embedding API â†’ Get 384-dim vector
   â”œâ”€> QdrantClient.search(query_vector, limit=k)
   â””â”€> Return top-k similar documents

3. If Knowledge Found:
   â”œâ”€> Build context from retrieved documents
   â”œâ”€> LlamaClient.generate(prompt with context)
   â””â”€> Append sources to response

4. If No Knowledge Found:
   â””â”€> Fallback to LLM Core (general sleep advice)

5. Return Response
   â””â”€> Contains: content, knowledge_sources, knowledge_used
```

### **Type 3: LLM Core Query**
Example: *"How can I improve my sleep?"*

```
1. QueryClassifier.classify()
   â””â”€> Returns: "LLM Core"

2. Check if Off-Topic:
   â”œâ”€> If yes: Use special prompt (acknowledge + redirect)
   â””â”€> If no: Use sleep advice prompt

3. LlamaClient.generate(prompt)
   â””â”€> POST to Llama API â†’ Stream response

4. Return Response
   â””â”€> Contains: content (formatted sleep advice)
```

### **Type 4: Off-Topic Query**
Example: *"What is the capital of Delhi?"*

```
1. QueryClassifier.is_sleep_related(query)
   â”œâ”€> Check sleep keywords
   â””â”€> Use Llama to verify â†’ Returns False

2. QueryClassifier.classify()
   â””â”€> Returns: "Off-Topic"

3. Route to LLM Core
   â””â”€> Use special prompt that:
       - Acknowledges Sleep Coach specialization
       - Briefly answers if possible
       - Suggests sleep-related help

4. Return Response
   â””â”€> Contains: content (polite redirect)
```

---

## ğŸ”§ Component Details

### **CustomEmbeddingClient**
```python
embed_query(text: str) â†’ List[float]
â”œâ”€> POST to Config.EMBEDDING_API_URL
â”œâ”€> Payload: {"text": text}
â””â”€> Returns: 384-dimensional embedding vector

embed_documents(texts: List[str]) â†’ List[List[float]]
â””â”€> Calls embed_query() for each text
```

### **LlamaClient**
```python
generate(prompt: str, timeout: int) â†’ str
â”œâ”€> POST to Config.LLAMA_API_URL
â”œâ”€> Payload: {"model": "llama3", "prompt": prompt, "stream": True}
â”œâ”€> Stream response chunks
â””â”€> Return complete response text
```

### **QueryClassifier**
```python
is_sleep_related(query: str) â†’ bool
â”œâ”€> Check sleep-related keywords
â””â”€> Use Llama if no keywords found

classify(query: str) â†’ str
â”œâ”€> Check sleep relevance first
â”œâ”€> Use Llama to classify into categories
â””â”€> Returns: "Data Pull (SQL)" | "Knowledge" | "LLM Core" | "Off-Topic"
```

### **SQLAgent**
```python
generate_sql(query: str, customer_id: str) â†’ str
â”œâ”€> Get database schema (dynamic column fetching)
â”œâ”€> Use Llama to generate SQL
â”œâ”€> Clean SQL (remove markdown, validate)
â””â”€> Auto-add GROUP BY if needed

run_query(sql_query: str) â†’ List[Dict]
â”œâ”€> Validate SELECT-only queries
â”œâ”€> Execute on MySQL
â”œâ”€> Serialize results (dates, decimals)
â””â”€> Return rows

format_sql_response(query, sql_query, results) â†’ str
â””â”€> Use Llama to format results into natural language
```

### **VectorDatabase (Qdrant)**
```python
add_documents(documents: List[Dict])
â”œâ”€> Extract texts and metadata
â”œâ”€> Generate embeddings (CustomEmbeddingClient)
â”œâ”€> Create PointStruct objects
â””â”€> Upsert to Qdrant collection

similarity_search(query: str, k: int) â†’ List[Dict]
â”œâ”€> Generate query embedding
â”œâ”€> Search Qdrant collection
â””â”€> Format results with content, source, score
```

---

## ğŸ” Privacy & Security Flow

### **PrivacyProcessor**
```
get_pseudo_id(user_id: str) â†’ str
â”œâ”€> Maps original user_id to pseudonymized ID
â””â”€> Stores in memory mapping (user_{uuid})

redact_pii(data: Dict) â†’ Dict
â””â”€> Removes PII fields (name, email, phone, etc.)
```

### **Data Flow with Privacy**
```
User Query (original customer_id)
    â†“
PrivacyProcessor.get_pseudo_id() â†’ pseudo_id (for logging)
    â†“
Database Query (uses original customer_id)
    â†“
Response (uses pseudo_id for logging)
```

---

## ğŸ“ Logging Flow

### **ConversationLogger**
```
log_interaction(user_pseudo_id, query, response)
â”œâ”€> Create session_id (date-based)
â”œâ”€> Redact sensitive data from response
â””â”€> Store in session history

get_session_history(user_pseudo_id) â†’ List[Dict]
â””â”€> Retrieve conversation history for user
```

---

## ğŸš€ API Endpoints Flow (FastAPI)

### **POST /query**
```
1. Receive QueryRequest {user_id, query}
2. Call sleep_coach.handle_user_query(user_id, query)
3. Return QueryResponse with:
   - response_type
   - content
   - sql_query (if applicable)
   - results (if applicable)
   - query_classification
   - knowledge_sources (if applicable)
```

### **POST /wearable**
```
1. Receive WearableDataRequest
2. Call sleep_coach.process_wearable_data(raw_data)
3. Store in AnalyticsDatabase
4. Return success status
```

### **POST /knowledge**
```
1. Receive KnowledgeDocumentRequest
2. Call sleep_coach.add_knowledge_documents(documents)
3. Embed documents and store in Qdrant
4. Return success status
```

---

## ğŸ”„ Error Handling Flow

### **Connection Failures**
```
MySQL Connection Failed
â””â”€> AnalyticsDatabase falls back to in-memory storage

Qdrant Connection Failed
â””â”€> VectorDatabase falls back to mock (returns default knowledge)

Llama API Failed
â””â”€> Returns error message in response.content

Embedding API Failed
â””â”€> Raises exception, falls back to mock knowledge base
```

### **Query Processing Errors**
```
SQL Generation Error
â””â”€> Returns user-friendly error message

SQL Execution Error
â””â”€> Returns empty results, logs error

Vector Search Error
â””â”€> Returns mock knowledge results

LLM Generation Error
â””â”€> Returns error message in response
```

---

## ğŸ“¦ Data Flow Summary

```
User Query
    â†“
[Privacy Processing]
    â†“
[Query Classification] â†’ Llama API
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Classification Branch               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  SQL Query:                          â”‚
â”‚    â†’ SQL Generation (Llama)         â”‚
â”‚    â†’ Database Query (MySQL)         â”‚
â”‚    â†’ Format Results                  â”‚
â”‚                                      â”‚
â”‚  Knowledge Query:                   â”‚
â”‚    â†’ Embed Query (Custom API)        â”‚
â”‚    â†’ Vector Search (Qdrant)          â”‚
â”‚    â†’ Generate Response (Llama)       â”‚
â”‚                                      â”‚
â”‚  LLM Core Query:                     â”‚
â”‚    â†’ Generate Response (Llama)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
[Response Formatting]
    â†“
[Logging]
    â†“
Return to User
```

---

## ğŸ› ï¸ Key Configuration Points

### **Environment Variables**
- `LLAMA_API_URL` - Required: Local Llama API endpoint
- `LLAMA_MODEL` - Llama model name (default: llama3)
- `QDRANT_URL` - Qdrant server URL (default: http://34.131.37.125:6333)
- `QDRANT_COLLECTION_NAME` - Collection name (default: docs)
- `EMBEDDING_API_URL` - Custom embedding service (default: http://34.131.37.125:8000/embed)
- `MYSQL_HOST`, `MYSQL_USER`, `MYSQL_PASSWORD`, `MYSQL_DATABASE` - MySQL config

### **Database Tables**
- `ai_coach_modules_summary` - User profiles and risk scores
- `ai_coach_daily_sleep_details` - Daily sleep metrics

---

## ğŸ“ˆ Performance Considerations

1. **Embedding Generation**: Sequential API calls (can be parallelized)
2. **SQL Generation**: Uses Llama with timeout (30-45s)
3. **Vector Search**: Fast with Qdrant (milliseconds)
4. **Database Queries**: Depends on MySQL performance
5. **LLM Generation**: Streams response for better UX

---

## ğŸ§ª Testing Flow

### **Demo Mode** (`main()` function)
```
1. Initialize SleepCoachLLM
2. Add knowledge documents
3. Process wearable data
4. Test different query types:
   - Personal data query
   - Cohort comparison
   - Knowledge query
```

---

This flow ensures proper separation of concerns, privacy handling, and scalable architecture for the Sleep Coach LLM system.

